{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbddb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the YouTube spam collection dataset available from OA 6.15. It is \n",
    "# a public set  of comments collected for spam research. It has five datasets\n",
    "# composed of 1956 real messages extracted from five videos. These five videos\n",
    "# are popular pop songs that were among  the 10 most viewed of the collection \n",
    "# period. All five datasets have the following attributes:  \n",
    "#\n",
    "#     • COMMENT_ID: unique id representing the comment  \n",
    "#     • AUTHOR: author ID  \n",
    "#     • DATE: date the comment is posted  \n",
    "#     • CONTENT: the comment  \n",
    "#     • TAG: for spam 1, otherwise 0.  \n",
    "#       \n",
    "# For this exercise use any four of these five datasets to build a spam filter\n",
    "# and use that  filter to check the accuracy on the remaining dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e64000bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Katy Perry dataset\n",
      "\n",
      "Results for multinomial distribution assumption:\n",
      "Accuracy: 0.9904761904761905\n",
      "[[59  0]\n",
      " [ 1 45]]\n",
      "\n",
      "Results for Gaussian distribution assumption:\n",
      "Accuracy: 1.0\n",
      "[[59  0]\n",
      " [ 0 46]]\n",
      "\n",
      "\n",
      "Psy dataset\n",
      "\n",
      "Results for multinomial distribution assumption:\n",
      "Accuracy: 0.9904761904761905\n",
      "[[55  1]\n",
      " [ 0 49]]\n",
      "\n",
      "Results for Gaussian distribution assumption:\n",
      "Accuracy: 1.0\n",
      "[[56  0]\n",
      " [ 0 49]]\n",
      "\n",
      "\n",
      "LMFAO dataset\n",
      "\n",
      "Results for multinomial distribution assumption:\n",
      "Accuracy: 0.9772727272727273\n",
      "[[56  2]\n",
      " [ 1 73]]\n",
      "\n",
      "Results for Gaussian distribution assumption:\n",
      "Accuracy: 1.0\n",
      "[[58  0]\n",
      " [ 0 74]]\n",
      "\n",
      "\n",
      "Shakira dataset\n",
      "\n",
      "Results for multinomial distribution assumption:\n",
      "Accuracy: 0.9819819819819819\n",
      "[[61  0]\n",
      " [ 2 48]]\n",
      "\n",
      "Results for Gaussian distribution assumption:\n",
      "Accuracy: 1.0\n",
      "[[61  0]\n",
      " [ 0 50]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1653 features, but MultinomialNB is expecting 1391 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Datasets/Code_and_Data_(Chapter_06)/Code and Data (Chapter 06)/YouTube-Spam-Collection-v1/Youtube04-Eminem.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m X, y \u001b[38;5;241m=\u001b[39m getXy(df)\n\u001b[1;32m---> 69\u001b[0m multi_preds \u001b[38;5;241m=\u001b[39m nb_multi\u001b[38;5;241m.\u001b[39mpredict(X) \n\u001b[0;32m     70\u001b[0m gauss_preds \u001b[38;5;241m=\u001b[39m nb_gauss\u001b[38;5;241m.\u001b[39mpredict(X) \n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Testing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:101\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m    102\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:574\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1653 features, but MultinomialNB is expecting 1391 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nb_multi = MultinomialNB() \n",
    "nb_gauss = GaussianNB()  \n",
    "\n",
    "# Text cleaning (consider additional steps like stop word removal)\n",
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "\n",
    "def getXy(df):\n",
    "    df['CONTENT'] = df['CONTENT'].apply(clean_text)\n",
    "\n",
    "    # Feature extraction using TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_transformed = vectorizer.fit_transform(df['CONTENT'])\n",
    "\n",
    "    # Use the transformed features for training\n",
    "    X = X_transformed.toarray()\n",
    "    y = df.CLASS\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Driver code\n",
    "def train_models(df, name):\n",
    "    X, y = getXy(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Build, train, and test a multinomial NB model\n",
    "    nb_multi.fit(X, y)\n",
    "    multi_preds = nb_multi.predict(X_test) \n",
    "\n",
    "    # Build, train, and test a gaussian NB model\n",
    "    nb_gauss.fit(X, y) \n",
    "    gauss_preds = nb_gauss.predict(X_test) \n",
    "    \n",
    "    print(f\"\\n\\n{name} dataset\")\n",
    "    \n",
    "    print(\"\\nResults for multinomial distribution assumption:\") \n",
    "    print(f\"Accuracy: {accuracy_score(y_test, multi_preds)}\")  \n",
    "    print(confusion_matrix(y_test, multi_preds)) \n",
    "    \n",
    "    print(\"\\nResults for Gaussian distribution assumption:\") \n",
    "    print(f\"Accuracy: {accuracy_score(y_test, gauss_preds)}\") \n",
    "    print(confusion_matrix(y_test, gauss_preds)) \n",
    "    \n",
    "# Train on four of the datasets\n",
    "df = pd.read_csv(\"../Datasets/Code_and_Data_(Chapter_06)/Code and Data (Chapter 06)/YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv\")\n",
    "train_models(df, \"Katy Perry\")\n",
    "\n",
    "df = pd.read_csv(\"../Datasets/Code_and_Data_(Chapter_06)/Code and Data (Chapter 06)/YouTube-Spam-Collection-v1/Youtube01-Psy.csv\")\n",
    "train_models(df, \"Psy\")\n",
    "\n",
    "df = pd.read_csv(\"../Datasets/Code_and_Data_(Chapter_06)/Code and Data (Chapter 06)/YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv\")\n",
    "train_models(df, \"LMFAO\")\n",
    "\n",
    "df = pd.read_csv(\"../Datasets/Code_and_Data_(Chapter_06)/Code and Data (Chapter 06)/YouTube-Spam-Collection-v1/Youtube05-Shakira.csv\")\n",
    "train_models(df, \"Shakira\")\n",
    "\n",
    "# Now predict on the last one\n",
    "df = pd.read_csv(\"../Datasets/Code_and_Data_(Chapter_06)/Code and Data (Chapter 06)/YouTube-Spam-Collection-v1/Youtube04-Eminem.csv\")\n",
    "X, y = getXy(df)\n",
    "multi_preds = nb_multi.predict(X) \n",
    "gauss_preds = nb_gauss.predict(X) \n",
    "\n",
    "print(f\"\\n\\nFinal Testing {name} dataset\")\n",
    "\n",
    "print(\"\\nResults for multinomial distribution assumption:\") \n",
    "print(f\"Accuracy: {accuracy_score(y, multi_preds)}\")  \n",
    "print(confusion_matrix(y, multi_preds)) \n",
    "\n",
    "print(\"\\nResults for Gaussian distribution assumption:\") \n",
    "print(f\"Accuracy: {accuracy_score(y, gauss_preds)}\") \n",
    "print(confusion_matrix(y, gauss_preds)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
