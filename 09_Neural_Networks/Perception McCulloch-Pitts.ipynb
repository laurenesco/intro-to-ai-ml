{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52166d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.78419346\n",
      "Iteration 2, loss = 0.40267290\n",
      "Iteration 3, loss = 0.35031849\n",
      "Iteration 4, loss = 0.20264795\n",
      "Iteration 5, loss = 0.16538864\n",
      "Iteration 6, loss = 0.13211615\n",
      "Iteration 7, loss = 0.11156361\n",
      "Iteration 8, loss = 0.09866746\n",
      "Iteration 9, loss = 0.08842021\n",
      "Iteration 10, loss = 0.08050207\n",
      "Iteration 11, loss = 0.07489158\n",
      "Iteration 12, loss = 0.06676060\n",
      "Iteration 13, loss = 0.06703796\n",
      "Iteration 14, loss = 0.04719479\n",
      "Iteration 15, loss = 0.04482522\n",
      "Iteration 16, loss = 0.05613746\n",
      "Iteration 17, loss = 0.04440638\n",
      "Iteration 18, loss = 0.05107588\n",
      "Iteration 19, loss = 0.03777104\n",
      "Iteration 20, loss = 0.04325680\n",
      "Iteration 21, loss = 0.06469638\n",
      "Iteration 22, loss = 0.05356171\n",
      "Iteration 23, loss = 0.03166770\n",
      "Iteration 24, loss = 0.04298037\n",
      "Iteration 25, loss = 0.04425011\n",
      "Iteration 26, loss = 0.04305164\n",
      "Iteration 27, loss = 0.04064673\n",
      "Iteration 28, loss = 0.03332480\n",
      "Iteration 29, loss = 0.02916529\n",
      "Iteration 30, loss = 0.02007766\n",
      "Iteration 31, loss = 0.01629264\n",
      "Iteration 32, loss = 0.01794930\n",
      "Iteration 33, loss = 0.01926230\n",
      "Iteration 34, loss = 0.02059684\n",
      "Iteration 35, loss = 0.02219854\n",
      "Iteration 36, loss = 0.02388542\n",
      "Iteration 37, loss = 0.02480484\n",
      "Iteration 38, loss = 0.03130864\n",
      "Iteration 39, loss = 0.02850014\n",
      "Iteration 40, loss = 0.03399336\n",
      "Iteration 41, loss = 0.02866019\n",
      "Iteration 42, loss = 0.01807346\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Multilayer Perceptron: Accuracy for training is 1.00\n",
      "Multilayer Perceptron: Accuracy for testing is 0.97\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary modules for fetching datasets, building a neural network model, splitting datasets, and evaluating model performance\n",
    "from sklearn.datasets import fetch_openml  \n",
    "from sklearn.neural_network import MLPClassifier  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import accuracy_score  \n",
    "\n",
    "# Fetching the MNIST dataset, which consists of 28x28 pixel images of handwritten digits, from OpenML\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, parser='auto')  \n",
    "\n",
    "# Normalizing the pixel values to be between 0 and 1 by dividing by the max pixel value (255),\n",
    "# and splitting the data into training and test sets with 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X/255., y, test_size=0.20, random_state=1) \n",
    "\n",
    "# Initializing a Multilayer Perceptron Classifier with specific hyperparameters:\n",
    "# - 'sgd' solver for weight optimization,\n",
    "# - maximum of 50 iterations for training,\n",
    "# - verbose output to see progress during training,\n",
    "# - a fixed random state for reproducibility,\n",
    "# - a learning rate of 0.1,\n",
    "# - and a network architecture with three layers of 784, 100, and 2 neurons respectively\n",
    "mlp = MLPClassifier(solver=\"sgd\", max_iter=50, verbose=True, random_state=1, learning_rate_init=.1, hidden_layer_sizes=(784, 100, 2))\n",
    "\n",
    "# Fitting (training) the MLP classifier on the training dataset\n",
    "mlp.fit(X_train, y_train) \n",
    "\n",
    "# Using the trained MLP classifier to predict labels for both the training and test datasets\n",
    "yhat_train_mlp = mlp.predict(X_train)  \n",
    "yhat_test_mlp = mlp.predict(X_test)  \n",
    "\n",
    "# Calculating the accuracy of the MLP classifier on the training set and printing the result\n",
    "print(\"Multilayer Perceptron: Accuracy for training is %.2f\" % (accuracy_score(y_train, yhat_train_mlp)))\n",
    "\n",
    "# Calculating the accuracy of the MLP classifier on the test set and printing the result\n",
    "print(\"Multilayer Perceptron: Accuracy for testing is %.2f\" % (accuracy_score(y_test, yhat_test_mlp))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44417507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
